# HR Attrition Analysis using PySpark

## Overview

This project aims to analyze HR attrition using a PySpark dataset sourced from Kaggle. The dataset provides valuable insights into employee attrition factors, allowing for a comprehensive analysis to better understand and mitigate attrition risks.

## Dataset

The dataset used in this analysis can be found on Kaggle: [HR Attrition Dataset](https://www.kaggle.com/code/mragpavank/ibm-hr-analytics-employee-attrition-performance/input). Make sure to download the dataset 
### Dataset Features

- `EmployeeID`: Unique identifier for each employee.
- `Age`: Age of the employee.
- `BusinessTravel`: Frequency of business travel.
- ... and more.....

## Requirements

Ensure you have the following dependencies installed:

- PySpark
- Jupyter Notebook (optional but recommended)

Install dependencies using:

```bash
pip install pyspark
```

## Getting Started

1. Clone the repository:

```bash
git clone https://github.com/your-username/hr-attrition-analysis.git
```

2. Download the Kaggle dataset

3. Run the Jupyter Notebook:

```bash
jupyter notebook HR_Attrition_Analysis.ipynb
```

4. Follow the analysis steps outlined in the notebook.

## Analysis Steps

The Jupyter Notebook (`HR_Attrition_Analysis.ipynb`) contains step-by-step analysis:

1. Data Loading
2. Exploratory Data Analysis (EDA)
3. Feature Engineering
4. Model Building
5. Evaluation and Interpretation
